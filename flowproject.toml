### flowproject.toml ###
### This file drives configuration options in sensorflow.py, ###
### by way of the file /flowproject/baseflow.py interface.   ###

# @project name
project_name = "demo_project"

[data]
# Get started in Outerbounds UI /Integrations tab. 
# Set the integration storage_type here. Choose from [snowflake, s3].
    # snowflake
        # integration
    # s3
        # role
# The type changes downstream options in data_kwargs too - will show below. 

### For Snowflake, set the type and the integration name.
# storage_type = "snowflake"
# integration = "weather-test"

### For S3, set the type and the IAM role arn.
storage_type = "s3"
role = "..."

[data_kwargs]
# This section is data.storage_type specific args.
# For example a sql "template" for the baseflow's _query_snowflake, or S3 bucket params.
# Required arguments by data.type:
    # snowflake
        # template
    # s3
        # bucket
        # key
        # check_mode

### For Snowflake
# template = "forecast"
# template = "sensor"

### For S3
# What to check for changes: 
    # "files_metadata": when the file metadata changes in a directory.
    # "file_modified_ts": when a specific file is modified in any way.
    # "file_size": when a specific file's size is changed.
bucket = "s3://demo-sensorflow"
key = "LICENSE"
check_mode = "file_modified_ts"

[sensor]
# run the sensor every `frequency` minutes
cron_schedule = "*/30 * * * *"

# [OPTIONAL] instead of using `@trigger_on_finish`,
# create an explicit event with this name
event_name = ""

# [OPTIONAL] supply the SQL response under this key
# in the event payload
payload_key = ""